

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>review3 &#8212; MAST90139 Multivariate Statistics for Data Science</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'review3.0';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="review4" href="review4.0.html" />
    <link rel="prev" title="review2" href="review2.0.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="_static/logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to MAST90138
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="basics.html">Notation</a></li>
<li class="toctree-l1"><a class="reference internal" href="resources.html">Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="progress.html">Progress Check</a></li>
<li class="toctree-l1"><a class="reference internal" href="comparison.html">Comparison</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week1.0.html">week1</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week1.1.html">Week 1 Lecture 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="week1.2.html">week1 lec 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="week1.3.html">week1 additional notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week2.0.html">week2</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week2.1.html">Week 2 Lecture 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="week2.2.html">Week 2 Lecture 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="week2.3.html">week2 additional notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week3.0.html">week3</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week3.1.html">Week 3 Lecture 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="week3.2.html">week3 lec 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="week3.3.html">week3 additional notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week4.0.html">week4</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week4.1.html">week4 lec 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="week4.2.html">week4 lec 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="week4.3.html">week4 additional notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week5.0.html">week5</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week5.1.html">week5 lec 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="week5.2.html">week5 lec2</a></li>
<li class="toctree-l2"><a class="reference internal" href="week5.3.html">week5 additional notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week6.0.html">Week 6</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week6.1.html">week6 lec1</a></li>
<li class="toctree-l2"><a class="reference internal" href="week6.2.html">week6 lec2</a></li>
<li class="toctree-l2"><a class="reference internal" href="week6.3.html">week 6 additional resources</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week7.0.html">week7</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week7.1.html">week7 lec1</a></li>
<li class="toctree-l2"><a class="reference internal" href="week7.2.html">week7 lec2</a></li>
<li class="toctree-l2"><a class="reference internal" href="week7.3.html">week7 additional notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week8.0.html">week8</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week8.1.html">week8 lec 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="week8.2.html">week8 lec 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="week8.3.html">week8 additional notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week9.0.html">week9</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week9.1.html">week9 lec 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="week9.2.html">week9 lec 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="week9.3.html">week9 additional notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week10.0.html">week10</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week10.1.html">week10 lec 1</a></li>
<li class="toctree-l2"><a class="reference internal" href="week10.2.html">week10 lec2</a></li>
<li class="toctree-l2"><a class="reference internal" href="week10.3.html">week10 additional notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week11.0.html">week11</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week11.1.html">week11. lec1</a></li>
<li class="toctree-l2"><a class="reference internal" href="week11.2.html">week11. lec2</a></li>
<li class="toctree-l2"><a class="reference internal" href="week11.3.html">week11 additional notes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="week12.0.html">week12</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="week12.1.html">CLUSTERING ALGORITHMS</a></li>
<li class="toctree-l2"><a class="reference internal" href="week12.2.html">week12 lec 2</a></li>
<li class="toctree-l2"><a class="reference internal" href="week12.3.html">week12 additional notes</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="review0.html">Review</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="review1.0.html">review1</a></li>
<li class="toctree-l2"><a class="reference internal" href="review2.0.html">review2</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">review3</a></li>
<li class="toctree-l2"><a class="reference internal" href="review4.0.html">review4</a></li>
<li class="toctree-l2"><a class="reference internal" href="review5.0.html">review5</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Freview3.0.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/review3.0.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>review3</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-models-binary">Classification Models (Binary)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-for-binary-classification">Linear Regression (for Binary Classification)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression-for-binary-classification">Logistic Regression (for Binary Classification)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-normal-gaussian">Multivariate Normal (Gaussian)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-discriminant-analysis-for-binary-classification">Linear Discriminant Analysis (for Binary Classification)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quadratic-discriminant-analysis-for-binary-classification">Quadratic Discriminant Analysis (for Binary Classification)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-rule-for-qa">Decision Rule for QA</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#starting-point-multivariate-normal-distribution">Starting Point: Multivariate Normal Distribution</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#incorporating-prior-probabilities">Incorporating Prior Probabilities</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#taking-the-logarithm">Taking the Logarithm</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-rule">Decision Rule</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization">Regularization</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="review3">
<h1>review3<a class="headerlink" href="#review3" title="Permalink to this heading">#</a></h1>
<section id="classification-models-binary">
<h2>Classification Models (Binary)<a class="headerlink" href="#classification-models-binary" title="Permalink to this heading">#</a></h2>
<p>Understood, here’s a simplified and correctly aligned version of the classification models:</p>
<section id="linear-regression-for-binary-classification">
<h3>Linear Regression (for Binary Classification)<a class="headerlink" href="#linear-regression-for-binary-classification" title="Permalink to this heading">#</a></h3>
<p>The probability model for class <span class="math notranslate nohighlight">\( G = 1 \)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[
m(x_1) = P(G = 1|X=x) = \beta_0 + \beta^T X
\]</div>
<p>For class <span class="math notranslate nohighlight">\( G = 2 \)</span>, the probability model is the complement of <span class="math notranslate nohighlight">\( m(x_1) \)</span>:</p>
<div class="math notranslate nohighlight">
\[
m(x_2) = 1 - m(x_1) = 1 - (\beta_0 + \beta^T X)
\]</div>
<p>The decision boundary where we classify <span class="math notranslate nohighlight">\( X \)</span> to <span class="math notranslate nohighlight">\( G = 1 \)</span> if:</p>
<div class="math notranslate nohighlight">
\[
\beta_0 + \beta^T X &gt; 1/2
\]</div>
</section>
<section id="logistic-regression-for-binary-classification">
<h3>Logistic Regression (for Binary Classification)<a class="headerlink" href="#logistic-regression-for-binary-classification" title="Permalink to this heading">#</a></h3>
<p>The probability model for class <span class="math notranslate nohighlight">\( G = 1 \)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[
m(x_1) = P(G = 1|X=x) = \frac{e^{\beta_0 + \beta^T X}}{1+e^{\beta_0 + \beta^T X}}
\]</div>
<p>For class <span class="math notranslate nohighlight">\( G = 2 \)</span>, the probability model is the complement of <span class="math notranslate nohighlight">\( m(x_1) \)</span>:</p>
<div class="math notranslate nohighlight">
\[
m(x_2) = 1 - m(x_1) = \frac{1}{1+e^{\beta_0 + \beta^T X}}
\]</div>
<p>The decision boundary where we classify <span class="math notranslate nohighlight">\( X \)</span> to <span class="math notranslate nohighlight">\( G = 1 \)</span> if:</p>
<div class="math notranslate nohighlight">
\[
\beta_0 + \beta^T X &gt; 0
\]</div>
<p>The last inequality comes from the fact that the logistic function yields a probability greater than 0.5 when <span class="math notranslate nohighlight">\( \beta_0 + \beta^T X &gt; 0 \)</span>, which is the condition for classifying <span class="math notranslate nohighlight">\( X \)</span> into <span class="math notranslate nohighlight">\( G = 1 \)</span> for logistic regression.</p>
</section>
</section>
<section id="multivariate-normal-gaussian">
<h2>Multivariate Normal (Gaussian)<a class="headerlink" href="#multivariate-normal-gaussian" title="Permalink to this heading">#</a></h2>
<p>For a univariate normal distribution, the probability density function (pdf) is given by:</p>
<div class="math notranslate nohighlight">
\[ f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right) \]</div>
<p>where <span class="math notranslate nohighlight">\( \mu \)</span> is the mean and <span class="math notranslate nohighlight">\( \sigma^2 \)</span> is the variance of the distribution.</p>
<p>For a multivariate normal distribution, the pdf becomes:</p>
<div class="math notranslate nohighlight">
\[ f(\mathbf{x}) = \frac{1}{\sqrt{(2\pi)^k|\Sigma|}} \exp\left(-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^T\Sigma^{-1}(\mathbf{x}-\boldsymbol{\mu})\right) \]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( \mathbf{x} \)</span> is a k-dimensional random vector.</p></li>
<li><p><span class="math notranslate nohighlight">\( \boldsymbol{\mu} \)</span> is the mean vector.</p></li>
<li><p><span class="math notranslate nohighlight">\( \Sigma \)</span> is the covariance matrix, which is a <span class="math notranslate nohighlight">\( k \times k \)</span> matrix.</p></li>
<li><p><span class="math notranslate nohighlight">\( |\Sigma| \)</span> is the determinant of the covariance matrix.</p></li>
<li><p><span class="math notranslate nohighlight">\( \Sigma^{-1} \)</span> is the inverse of the covariance matrix.</p></li>
</ul>
<p>The term <span class="math notranslate nohighlight">\( (\mathbf{x}-\boldsymbol{\mu})^T\Sigma^{-1}(\mathbf{x}-\boldsymbol{\mu}) \)</span> is a quadratic form which generalizes the squared difference term <span class="math notranslate nohighlight">\( (x-\mu)^2 \)</span> from the univariate case. Here’s why the matrix form is used:</p>
<ol class="arabic simple">
<li><p><strong>Covariance</strong>: In multiple dimensions, not only do we have variances along each dimension (akin to <span class="math notranslate nohighlight">\( \sigma^2 \)</span> in the univariate case), but we also have covariances between each pair of dimensions. The covariance matrix <span class="math notranslate nohighlight">\( \Sigma \)</span> encapsulates all this information.</p></li>
<li><p><strong>Quadratic Form</strong>: The quadratic form <span class="math notranslate nohighlight">\( (\mathbf{x}-\boldsymbol{\mu})^T\Sigma^{-1}(\mathbf{x}-\boldsymbol{\mu}) \)</span> measures the squared distance of <span class="math notranslate nohighlight">\( \mathbf{x} \)</span> from the mean <span class="math notranslate nohighlight">\( \boldsymbol{\mu} \)</span>, weighted by the covariance structure. The transpose <span class="math notranslate nohighlight">\( (\mathbf{x}-\boldsymbol{\mu})^T \)</span> and the inverse covariance matrix <span class="math notranslate nohighlight">\( \Sigma^{-1} \)</span> are used to properly account for the orientation and scaling dictated by the covariance between the variables.</p></li>
<li><p><strong>Determinant and Inverse</strong>: The determinant <span class="math notranslate nohighlight">\( |\Sigma| \)</span> serves to normalize the distribution so that the total probability integrates to 1. The inverse <span class="math notranslate nohighlight">\( \Sigma^{-1} \)</span> is used in the quadratic form to account for the correlation structure between the variables.</p></li>
</ol>
<div class="admonition-assumption admonition">
<p class="admonition-title">Assumption</p>
<ol class="arabic simple">
<li><p>LDA assumes that both classes share the same covariance matrix, which results in a linear decision boundary.</p></li>
<li><p>Normal distribution.</p></li>
</ol>
</div>
<section id="linear-discriminant-analysis-for-binary-classification">
<h3>Linear Discriminant Analysis (for Binary Classification)<a class="headerlink" href="#linear-discriminant-analysis-for-binary-classification" title="Permalink to this heading">#</a></h3>
<p><strong>Bayes</strong></p>
<div class="math notranslate nohighlight">
\[P(G = k |X = x) = \frac{P(X = x|G = k )\pi_k}{P(X=x)}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\pi_k = P(G = k)\)</span>.</p>
<p>The probability model for class <span class="math notranslate nohighlight">\( G = 1 \)</span> is given by a Gaussian distribution with mean <span class="math notranslate nohighlight">\( \mu_1 \)</span> and common covariance matrix <span class="math notranslate nohighlight">\( \Sigma \)</span>:</p>
<div class="math notranslate nohighlight">
\[
m(x_1) = P(G = 1|X=x) \propto \exp\left(-\frac{1}{2}(x - \mu_1)^T \Sigma^{-1}(x - \mu_1)\right)
\]</div>
<p>Similarly, for class <span class="math notranslate nohighlight">\( G = 2 \)</span>, the probability model is a Gaussian distribution with mean <span class="math notranslate nohighlight">\( \mu_2 \)</span> and the same common covariance matrix <span class="math notranslate nohighlight">\( \Sigma \)</span>:</p>
<div class="math notranslate nohighlight">
\[
m(x_2) = P(G = 2|X=x) \propto \exp\left(-\frac{1}{2}(x - \mu_2)^T \Sigma^{-1}(x - \mu_2)\right)
\]</div>
<p>The decision boundary for LDA is derived by setting the log of the ratio of these probabilities equal to zero, which simplifies to a linear function in <span class="math notranslate nohighlight">\( x \)</span> due to the common covariance matrix:</p>
<div class="math notranslate nohighlight">
\[
\log\left(\frac{m(x_1)}{m(x_2)}\right) = 0
\]</div>
<p>This simplifies further to the linear equation:</p>
<div class="math notranslate nohighlight">
\[
(x - \mu_1)^T \Sigma^{-1}(x - \mu_1) - (x - \mu_2)^T \Sigma^{-1}(x - \mu_2) = 0
\]</div>
<p>Which can be simplified to:</p>
<div class="math notranslate nohighlight">
\[
x^T \Sigma^{-1}(\mu_1 - \mu_2) - \frac{1}{2}(\mu_1 + \mu_2)^T \Sigma^{-1}(\mu_1 - \mu_2) + \log\left(\frac{\pi_1}{\pi_2}\right) = 0
\]</div>
<p>Here, <span class="math notranslate nohighlight">\( \mu_1 \)</span> and <span class="math notranslate nohighlight">\( \mu_2 \)</span> are the mean vectors for each class, <span class="math notranslate nohighlight">\( \Sigma \)</span> is the shared covariance matrix, and <span class="math notranslate nohighlight">\( \pi_1 \)</span> and <span class="math notranslate nohighlight">\( \pi_2 \)</span> are the prior probabilities of each class.</p>
<p>The resulting decision boundary is a hyperplane in the feature space, and the side of the hyperplane an observation falls on determines the predicted class for that observation. The term <span class="math notranslate nohighlight">\( x^T \Sigma^{-1}(\mu_1 - \mu_2) \)</span> represents the projection of the difference in class means onto the data, and it is this projection that is used for classification.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>What if data is non-linearly separable?
Use QD (instead of LD)!</p>
</div>
</section>
<section id="quadratic-discriminant-analysis-for-binary-classification">
<h3>Quadratic Discriminant Analysis (for Binary Classification)<a class="headerlink" href="#quadratic-discriminant-analysis-for-binary-classification" title="Permalink to this heading">#</a></h3>
<p>In QDA, each class <span class="math notranslate nohighlight">\( G = 1 \)</span> and <span class="math notranslate nohighlight">\( G = 2 \)</span> has its own covariance matrix, which allows for the modeling of more complex decision boundaries.</p>
<p>The probability model for class <span class="math notranslate nohighlight">\( G = 1 \)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[
m(x_1) = P(G = 1|X=x) \propto \exp\left(-\frac{1}{2}(x - \mu_1)^T \Sigma_1^{-1}(x - \mu_1)\right)
\]</div>
<p>For class <span class="math notranslate nohighlight">\( G = 2 \)</span>, the probability model is:</p>
<div class="math notranslate nohighlight">
\[
m(x_2) = P(G = 2|X=x) \propto \exp\left(-\frac{1}{2}(x - \mu_2)^T \Sigma_2^{-1}(x - \mu_2)\right)
\]</div>
<p>The decision boundary is found by setting <span class="math notranslate nohighlight">\( m(x_1) = m(x_2) \)</span> and solving for <span class="math notranslate nohighlight">\( x \)</span>. In practice, this means finding the <span class="math notranslate nohighlight">\( x \)</span> such that:</p>
<div class="math notranslate nohighlight">
\[
-\frac{1}{2}(x - \mu_1)^T \Sigma_1^{-1}(x - \mu_1) + \log(\pi_1) = -\frac{1}{2}(x - \mu_2)^T \Sigma_2^{-1}(x - \mu_2) + \log(\pi_2)
\]</div>
</section>
<section id="decision-rule-for-qa">
<h3>Decision Rule for QA<a class="headerlink" href="#decision-rule-for-qa" title="Permalink to this heading">#</a></h3>
<p>The quadratic discriminant function <span class="math notranslate nohighlight">\(\delta_k(x)\)</span> in Quadratic Discriminant Analysis (QDA) is derived from the likelihood of the data given a particular class, under the assumption that the data in each class follow a multivariate normal (Gaussian) distribution. Here’s a step-by-step explanation of how <span class="math notranslate nohighlight">\(\delta_k(x)\)</span> is obtained:</p>
<section id="starting-point-multivariate-normal-distribution">
<h4>Starting Point: Multivariate Normal Distribution<a class="headerlink" href="#starting-point-multivariate-normal-distribution" title="Permalink to this heading">#</a></h4>
<p>For a K-class problem, each class <span class="math notranslate nohighlight">\( k \)</span> is assumed to follow a multivariate normal distribution with its own mean vector <span class="math notranslate nohighlight">\( \mu_k \)</span> and covariance matrix <span class="math notranslate nohighlight">\( \Sigma_k \)</span>. The probability density function of a multivariate normal distribution is given by:</p>
<div class="math notranslate nohighlight">
\[
f(x | \mu_k, \Sigma_k) = \frac{1}{(2\pi)^{n/2} |\Sigma_k|^{1/2}} \exp \left( -\frac{1}{2} (x - \mu_k)^T \Sigma_k^{-1} (x - \mu_k) \right)
\]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( x \)</span> is the data point.</p></li>
<li><p><span class="math notranslate nohighlight">\( \mu_k \)</span> is the mean vector for class <span class="math notranslate nohighlight">\( k \)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\( \Sigma_k \)</span> is the covariance matrix for class <span class="math notranslate nohighlight">\( k \)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\( |\Sigma_k| \)</span> is the determinant of <span class="math notranslate nohighlight">\( \Sigma_k \)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\( \Sigma_k^{-1} \)</span> is the inverse of <span class="math notranslate nohighlight">\( \Sigma_k \)</span>.</p></li>
</ul>
</section>
<section id="incorporating-prior-probabilities">
<h4>Incorporating Prior Probabilities<a class="headerlink" href="#incorporating-prior-probabilities" title="Permalink to this heading">#</a></h4>
<p>In QDA, we also consider the prior probabilities of each class <span class="math notranslate nohighlight">\( \pi_k \)</span>. The overall likelihood of a data point <span class="math notranslate nohighlight">\( x \)</span> belonging to class <span class="math notranslate nohighlight">\( k \)</span> is the product of its class-conditional density and the class prior probability:</p>
<p>Since <span class="math notranslate nohighlight">\(lnP(x)\)</span> is the same for all classes, it does not influence which class maximizes <span class="math notranslate nohighlight">\(lnP(k∣x)\)</span>. Therefore, it can be ignored in the decision rule, which leads to the simplified formula (with application of Bayes):</p>
<div class="math notranslate nohighlight">
\[
P(k | x) \propto \pi_k f(x | \mu_k, \Sigma_k)
\]</div>
</section>
<section id="taking-the-logarithm">
<h4>Taking the Logarithm<a class="headerlink" href="#taking-the-logarithm" title="Permalink to this heading">#</a></h4>
<p>To simplify calculations and avoid numerical underflow, we take the logarithm of this expression, leading to the log-likelihood:</p>
<div class="math notranslate nohighlight">
\[
\ln P(k | x) = \ln \pi_k + \ln f(x | \mu_k, \Sigma_k)
\]</div>
<p>Plugging in the expression for <span class="math notranslate nohighlight">\( f(x | \mu_k, \Sigma_k) \)</span> and simplifying, we get:</p>
<div class="math notranslate nohighlight">
\[
\ln P(k | x) = \ln \pi_k - \frac{1}{2} \ln |\Sigma_k| - \frac{1}{2} (x - \mu_k)^T \Sigma_k^{-1} (x - \mu_k) - \text{constant}
\]</div>
<p>Since the constant term (involving <span class="math notranslate nohighlight">\((2\pi)^{n/2}\)</span>) is the same for all classes and does not affect the classification decision, it can be omitted. This gives us the quadratic discriminant function for class <span class="math notranslate nohighlight">\( k \)</span>:</p>
<div class="math notranslate nohighlight">
\[
\delta_k(x) = \ln \pi_k - \frac{1}{2} \ln |\Sigma_k| - \frac{1}{2} (x - \mu_k)^T \Sigma_k^{-1} (x - \mu_k)
\]</div>
</section>
<section id="decision-rule">
<h4>Decision Rule<a class="headerlink" href="#decision-rule" title="Permalink to this heading">#</a></h4>
<p>Finally, the decision rule in QDA is to assign the observation <span class="math notranslate nohighlight">\( x \)</span> to the class that maximizes <span class="math notranslate nohighlight">\(\delta_k(x)\)</span>, which is equivalent to maximizing the log-likelihood <span class="math notranslate nohighlight">\( \ln P(k | x) \)</span>. This accounts for both the shape of the class distribution (through the covariance matrix) and the prior probability of each class.</p>
</section>
</section>
<section id="regularization">
<h3>Regularization<a class="headerlink" href="#regularization" title="Permalink to this heading">#</a></h3>
<p>Regularized Quadratic Discriminant Analysis (QDA) is an extension of QDA that addresses the potential problem of overfitting, especially in situations where the number of features is large compared to the number of observations, or when the class covariance matrices are nearly singular.</p>
<p>In regular QDA, you estimate the covariance matrices for each class separately, which can lead to models that are very flexible but also prone to overfitting the data. Regularization introduces a shrinkage parameter, which essentially pulls the class-specific covariance matrices towards a common covariance matrix or towards the identity matrix (which would imply independence of the features).</p>
<p>Here’s a bit more detail on how it works:</p>
<ol class="arabic">
<li><p><strong>Covariance Estimation</strong>: In standard QDA, the covariance matrix for each class <span class="math notranslate nohighlight">\( \Sigma_k \)</span> is estimated directly from the data corresponding to that class.</p></li>
<li><p><strong>Regularization</strong>: In regularized QDA, you adjust each <span class="math notranslate nohighlight">\( \Sigma_k \)</span> by pulling it towards a central estimate <span class="math notranslate nohighlight">\( \Sigma \)</span> or towards the identity matrix <span class="math notranslate nohighlight">\( I \)</span>. The extent to which you do this is controlled by a regularization parameter <span class="math notranslate nohighlight">\( \lambda \)</span> (which can be between 0 and 1).</p></li>
<li><p><strong>Regularized Covariance Matrix</strong>: The regularized covariance matrix for each class <span class="math notranslate nohighlight">\( k \)</span> can be calculated as:</p>
<div class="math notranslate nohighlight">
\[
   \hat{\Sigma}_k = (1 - \lambda) \Sigma_k + \lambda \Sigma
   \]</div>
<p>where <span class="math notranslate nohighlight">\( \Sigma \)</span> could be the average of all the <span class="math notranslate nohighlight">\( \Sigma_k \)</span> (the pooled covariance matrix), or it could be the identity matrix if you’re regularizing towards independence.</p>
</li>
<li><p><strong>Logarithmic Loss with Regularization</strong>: The regularization modifies the discriminant function by changing the covariance matrices used in the function. The regularized discriminant function incorporates the regularized covariance matrices to compute the probability that an observation belongs to each class.</p></li>
<li><p><strong>Choosing <span class="math notranslate nohighlight">\( \lambda \)</span></strong>: The regularization parameter <span class="math notranslate nohighlight">\( \lambda \)</span> is typically chosen through cross-validation to optimize the model’s predictive performance on unseen data.</p></li>
</ol>
<p>Regularization helps to improve the model’s generalizability and robustness by preventing it from being overly complex relative to the amount of training data. It is particularly useful when the data contains redundant features or when there is collinearity among the features.</p>
<hr class="docutils" />
<ul class="simple">
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=SWfucxnOF8c">Partial least squares regression (PLSR) - explained</a></p></li>
<li><p>Similar to principal component regression, the method of partial least squares, also called projection to latent structures, is a technique that reduces the number of explanatory variables to a smaller set of uncorrelated variables.</p></li>
<li><p>Both methods are used to overcome the problem with collinearity in linear regression and in cases where we have more explanatory variables than observations. Watch the lecture about principal component regression for more information.</p></li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="review2.0.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">review2</p>
      </div>
    </a>
    <a class="right-next"
       href="review4.0.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">review4</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-models-binary">Classification Models (Binary)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-for-binary-classification">Linear Regression (for Binary Classification)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#logistic-regression-for-binary-classification">Logistic Regression (for Binary Classification)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-normal-gaussian">Multivariate Normal (Gaussian)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-discriminant-analysis-for-binary-classification">Linear Discriminant Analysis (for Binary Classification)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quadratic-discriminant-analysis-for-binary-classification">Quadratic Discriminant Analysis (for Binary Classification)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-rule-for-qa">Decision Rule for QA</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#starting-point-multivariate-normal-distribution">Starting Point: Multivariate Normal Distribution</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#incorporating-prior-probabilities">Incorporating Prior Probabilities</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#taking-the-logarithm">Taking the Logarithm</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-rule">Decision Rule</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization">Regularization</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Jiahe Liu (jiahe3@student.unimelb.edu.au)
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>