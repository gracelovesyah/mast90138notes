# Welcome to MAST90138 

This is a small notebook to MAST90138 Multivariate Stats for Data Science @ Unimelb

This note is composed by Jiahe (Grace) Liu (jiahe3@student.unimelb.edu.au) with assistance of ChatGPT.
# Table of Contents

1. INTRODUCTION

2. REVIEW OF MATRIX PROPERTIES

   2.1. Elementary Operations

   2.2. Spectral Decompositions

   2.3. Quadratic Forms

   2.4. Geometrical Aspects

3. MEAN, COVARIANCE, CORRELATION

   3.1. Mean

   3.2. Covariance Matrix

   3.3. Correlation Matrix

   3.4. Linear Transformations

4. MULTIVARIATE DISTRIBUTIONS

   4.1. Distribution and Density Function

   4.2. Multinormal Distribution

   4.3. Wishart Distribution

   4.4. Hotelling's T-squared Distribution

5. PRINCIPAL COMPONENT ANALYSIS

   5.1. Introduction

   5.2. PCA: More Formally

   5.3. In Practice

   5.4. Interpretation of the PCs

   5.5. Normalised PCA

   5.6. Example

   5.7. PCA with Regression

   5.8. Partial Least Squares

   5.9. Discussion

6. FACTOR ANALYSIS

   6.1. Orthogonal Factor Model

   6.2. Interpreting the Factors

   6.3. Scaling the Data

   6.4. Non Unicity of the Matrix Q

   6.5. Likelihood Methods under Normal Assumption

   6.6. Rotation

   6.7. Factor Scores

7. LINEAR AND QUADRATIC CLASSIFICATION

   7.1. Introduction to Classification
   
   7.2. Main Ideas of Classification Techniques

   7.3. Simple Regression Approaches for K = 2 Classes

    7.3.1. Linear Regression Classifier

    7.3.2. Logistic Regression Classifier

   7.4. Bayes Methods for K = 2 Classes: Linear and Quadratic Discriminant

    7.4.1. Linear Discriminant (LD)

    7.4.2. Quadratic Discriminant (QD)

   7.5. Simple Regression Approaches for K > 2 Classes

    7.5.1. Linear Regression for K > 2 Classes

    7.5.2. Logistic Regression for K > 2 Classes

    7.5.3. LD and QD Methods for K > 2 Groups

8. CLASSIFICATION AND REGRESSION TREES AND RELATED METHODS

   8.1. Classification and Regression Trees (CART)

    8.1.1. Introduction

    8.1.2. Regression Trees

    8.1.3. Classification Trees

    8.1.4. Example: Spam Data

   8.2. Bagging Classification Trees

   8.3. Random Forests for Classification

    8.3.1. Out of Bag Data

    8.3.2. Variable Importance

    8.3.3. A Few Remarks on the Performance of RF

9. CLUSTER ANALYSIS

   9.1. Introduction

   9.2. Dissimilarity Matrices

   9.3. Dissimilarities Based on Attributes

   9.4. Object Dissimilarity

   9.5. Clustering Algorithms

   9.6. Combinatorial Algorithms

   9.7. K-means Algorithm

   9.8. K-medoids Algorithm

   9.9. How to Choose K in a Clustering Method?

Check out the content pages bundled with this sample book to see more.

```{tableofcontents}
```
